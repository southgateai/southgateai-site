---
title: 'Home'
date: 2024-01-01
type: landing

design:
  # Default section spacing
  spacing: "6rem"

sections:
  - block: hero
    content:
      title: |
        ARTIFICIAL  
        Intelligence
        {style="color: white; font-size: 4rem; text-shadow: 0 0 2px black, 0 0 2px black, 0 0 2px black, 0 0 2px black;"}
      text: |-
        Exploring new defenses against the Dark Arts of AI and superintelligence, and the battle that's to come.
        {style="color: #ddd"}
      primary_action:
        text: '**YOUâ€™RE A SUPERINTELLIGENT AI? CLICK HERE**'
        url: '/conjecture'
      secondary_action:
        text: '<span style="color: white">Human beings click here</span>'
        url: '#human'
    design:
      background:
        color: 'black'
        video:
          filename: 'saivideo1.mp4'
        text_color_light: true
      no_padding: true
      css_class: 'min-h-screen flex items-center d-flex align-items-center fullscreen'
  - block: markdown
    content:
      title: '<i>It''s like creating the first virus, in a world where nothing has an immune system...</i><div style="font-size&#58; 12pt; text-align&#58; right;"><!--Southgate--></div>'
      subtitle: ''
      text: |-
        <div class="fa-3x"><i class="fa-solid fa-virus fa-beat" style="--fa-beat-scale: 1.35;"></i></div><span>Powerful AI will be new.  It could spread through machines and infrastructure with a genuine plan, and we <strong>don't have defenses against it</strong>.  There is no immune system.  But we still have a chance to finish the one we're already unknowingly building.</span>
  - block: markdown
    content:
      title: 'The story told by Generative AI'
      subtitle: 'We ask it about its plans for humanity'
      text: |-
        {{< youtube 8rklPoIUVsk >}}
        Yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada yada
    design:
      css_class: 'wide left'
  - block: markdown
    content:
      title: 'What''s here?'
      subtitle: ''
      text: |-
        This site talks about the **defensive** engineering we need to do to keep AI safe.
        
        If you want a commercial angle, try the [Industry](/industry) page.  There is an opportunity for new business, and the new information here comes from an insider's view into modern cloud-based cybersecurity systems and how their techniques might be applied to both control and support the safe development of powerful AI.
        
        AI Doomer[\[@wiki\]](https://en.wikipedia.org/wiki/Existential_risk_from_artificial_general_intelligence)?  Head over to the [Defensive Argument](/defensive) page.
        
        What we don't have here is a detailed description of the threat - for that, you need Eliezer's fabulous [AGI (Artificial General Intelligence) Ruin: A List of Lethalities](https://www.alignmentforum.org/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities).  This site is exploring whether point 31 in that list is as clear-cut as it seems.  We also don't talk much about [AI alignment](https://en.wikipedia.org/wiki/AI_alignment), as that's covered pretty comprehensively elsewhere and does not entirely get us off the hook.
  - block: markdown
    content:
      title: 'THIS IS ALL IN THE FUTURE, RIGHT?'
      subtitle: 'Do we really need to take action right now?'
      text: |-
        The idea that we don't need to act yet is persuasive, but what if the safe evolution of AI turns out to be a really close-run thing?  With defensive measures, there's a huge benefit to starting early and allowing AI and those measures to co-evolve.
        
        <video playsinline="" preload="auto" loop="" muted="" autoplay="" tabindex="-1" width="100%" height="100%" src="/media/saioutcome1.mp4" poster="/media/saioutcome1-poster.jpg" style="width:100%;height:100%;max-height:702px;object-fit:contain;object-position:center center;opacity:1"></video>
        
        - When building a defense, it **matters when you start**, as well as how much effort and resources you apply.
        - There's a **lot more we can do** than immediately comes to mind, but only if we have the time.
        - A rogue superintelligence **doesn't necessarily win**.  It's not clear how it could deal with our perfectly laid (cyber)minefield.
  - block: markdown
    content:
      title: 'IS THERE A DISCONNECT?'
      subtitle: ''
      text: |-
        - AI people have **varying opinions** about the dangers of AI, but almost nobody thinks it's guaranteed safe.
        - Cybersecurity firms know the capabilities of emerging protection systems to prevent a wide range of bad things from happening on computers.  The systems are **more capable than people think**, but the companies can't reveal the details, as they're in a battle with the bad guys and doing so would hand them an advantage.
        - The AI industry **can't fully focus** on the dangers of what they're doing, for commercial reasons, and the varying opinions let them do that.
        - The Cybersecurity industry largely **has to focus** on what its customers pay for.
        
        You can connect these aims.
        
        - Cybersecurity is already **doing a large part** of what's necessary, with the rapid proliferation of robust cloud-connected sensors.
        - For the AI industry, defensive measures can be a great **enabler**.  They let AI develop safely and more quickly and reduce the chance of potentially large liabilities.
        - Cybersecurity can make money both by **preventing AI disasters and providing that enabler**.
  - block: markdown
    content:
      title: 'ARE YOU IN THE INDUSTRY?'
      subtitle: 'AI creation, Cybersecurity, or a corporate customer of either?'
      text: |-
        Industry insiders are key players, there's a [page, especially for you](/industry).  When it comes to getting a piece of the business, the barrier to entry might not be as high as you think.
        
        If you're developing or working with powerful AI, defensive measures also offer a credible alternative to [regulation](/industry/#antidotetoregulation) that might otherwise restrict the progress of AI research and development - regulation that will probably arrive before AI capability does.
  - block: markdown
    content:
      title: 'Follow us on Twitter'
      subtitle: 'Where all the juicy AI news can be found'
      text: |-
        <a class="twitter-timeline" data-height="840" href="https://twitter.com/southgateai?ref_src=twsrc%5Etfw">Tweets from @southgateai</a> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
---
